<!-- livebook:{"persist_outputs":true} -->

# Fine-tuning

```elixir
Mix.install([
  {:bumblebee, "~> 0.4.2"},
  {:axon, "~> 0.6.0"},
  {:nx, "~> 0.6.1"},
  {:exla, "~> 0.6.1"},
  {:explorer, "~> 0.7.0"},
  {:lorax, path: "/Users/ted/CS/elixir/lorax"},
  {:req, "~> 0.4.0"},
  {:kino, "~> 0.11.0"}
])

Nx.default_backend(EXLA.Backend)
```

## Introduction

Fine-tuning is the process of specializing the parameters in a pre-trained model to a specific task. Large-language models such as BERT train on a generic langauge-modeling task which makes them powerful at extracting features from text. Despite their power, you often still need to train them on a downstream task.

This example demonstrates how to use Bumblebee and Axon to fine-tune a pre-trained Bert model to classify Yelp reviews into classes of 1-5 stars. This example is based on [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training) from Huggingface.

You'll need to first download the Yelp Reviews dataset ([download](https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz)).

Once downloaded, extract it to a directory of your choosing and you're ready to go!

## Load a model

We'll start by loading a pre-trained model and tokenizer; however, we'll initialize the model to have an untrained sequence classification head.

Reviews in the dataset can have anywhere from 1 to 5 stars, which means we need 5 labels in our sequence classification head. We can change the default configuration by loading the model spec with `Bumblebee.load_spec/2` and making changes to spec properties with `Bumblebee.configure/2`.

The pre-trained model we'll be using is `bert-base-cased`; however, you can use any of the supported models from the HuggingFace Hub.

```elixir
{:ok, spec} = Bumblebee.load_spec({:hf, "gpt2"})
{:ok, model} = Bumblebee.load_model({:hf, "gpt2"}, spec: spec)
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "gpt2"})
```

<!-- livebook:{"output":true} -->

```

21:14:19.868 [info] TfrtCpuClient created.

```

<!-- livebook:{"output":true} -->

```
{:ok,
 %Bumblebee.Text.Gpt2Tokenizer{
   tokenizer: #Tokenizers.Tokenizer<[
     vocab_size: 50257,
     byte_fallback: false,
     continuing_subword_prefix: "",
     dropout: nil,
     end_of_word_suffix: "",
     fuse_unk: false,
     model_type: "bpe",
     unk_token: nil
   ]>,
   special_tokens: %{
     pad: "<|endoftext|>",
     bos: "<|endoftext|>",
     eos: "<|endoftext|>",
     unk: "<|endoftext|>"
   },
   additional_special_tokens: []
 }}
```

```elixir
# text = Kino.Input.textarea("Text Data")
text =
  Req.get!(
    "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
  ).body
```

<!-- livebook:{"output":true} -->

```
"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\nSecond Citizen:\nWould you proceed especially against Caius Marcius?\n\nAll:\nAgainst him first: he's a very dog to the commonalty.\n\nSecond Citizen:\nConsider you what services he has done for his country?\n\nFirst Citizen:\nVery well; and could be content to give him good\nreport fort, but that he pays himself with being proud.\n\nSecond Citizen:\nNay, but speak not maliciously.\n\nFirst Citizen:\nI say unto you, what he hath done famously, he did\nit to that end: though soft-conscienced men can be\ncontent to say it was for his country he did it to\nplease his mother and to be partly proud; which he\nis, even till the altitude of his virtue.\n\nSecond Citizen:\nWhat he cannot help in his nature, you account a\nvice in him. You must in no way say he is covetous.\n\nFirst Citizen:\nIf I must not, I need not be barren of accusations;\nhe hath faults, with surplus, to tire in repetition.\nWhat shouts are these? The other side o' the city\nis risen: why stay we prating here? to the Capitol!\n\nAll:\nCome, come.\n\nFirst Citizen:\nSoft! who comes here?\n\nSecond Citizen:\nWorthy Menenius Agrippa; one that hath always loved\nthe people.\n\nFirst Citizen:\nHe's one honest enough: would all the rest were so!\n\nMENENIUS:\nWhat work's, my countrymen, in hand? where go you\nWith bats and clubs? The matter? speak, I pray you.\n\nFirst Citizen:\nOur business is not unknown to the senate; they have\nhad inkling this fortnight what we intend to do,\nwhich now we'll show 'em in deeds. They say poor\nsuitors have strong breaths: they shall know we\nhave strong arms too.\n\nMENENIUS:\nWhy, masters, my good friends, mine honest neighbours,\nWill you undo yourselves?\n\nFirst Citizen:\nWe cannot, sir, we are undone already.\n\nMENENIUS:\nI tell you, friends, most charitable care\nHave the patricians of you. For your wants,\nYour suffering in this dearth, you may as well\nStrike at the heaven with your staves as lift them\nAgainst the Roman state, whose course will on\nThe way it takes, cracking ten thousand curbs\nOf more strong link asunder than can ever\nAppear in your impediment. For the dearth,\nThe gods, not the patricians, make it, and\nYour knees to them, not arms, must help. Alack,\nYou are transported by calamity\nThither where more attends you, and you slander\nThe helms o' the state, who care for you like fathers,\nWhen you curse them as enemies.\n\nFirst Citizen:\nCare for us! True, indeed! They ne'er cared for us\nyet: suffer us to famish, and their store-houses\ncrammed with grain; make edicts for usury, to\nsupport usurers; repeal daily any wholesome act\nestablished against the rich, and provide more\npiercing statutes daily, to chain up and restrain\nthe poor. If the wars eat us not up, they will; and\nthere's all the love they bear us.\n\nMENENIUS:\nEither you must\nConfess yourselves wondrous malicious,\nOr be accused of folly. I shall tell you\nA pretty tale: it may be you have heard it;\nBut, since it serves my purpose, I will venture\nTo stale 't a little more.\n\nFirst Citizen:\nWell, I'll hear it, sir: yet you must not think to\nfob off our disgrace with a tale: but, an 't please\nyou, deliver.\n\nMENENIUS:\nThere was a time when all " <> ...
```

## Prepare a dataset

With the models downloaded and ready to go, you need to prepare the dataset. The downloaded dataset is a CSV. You can use the `Explorer` library to quickly load the CSV into a DataFrame.

Once the data is loaded, you need to convert raw text to tokens and the raw labels to tensors. Additionally, you need to convert the DataFrame to a Stream consisting of tuples: `{tokenized, labels}` - that is the form expected by Axon's training API.

<!-- livebook:{"break_markdown":true} -->

Now you can use the `Yelp.load/2` function to load a training set and a testing set:

```elixir
batch_size = 4
sequence_length = 64

tokenized_text = %{"input_ids" => input_ids} = Bumblebee.apply_tokenizer(tokenizer, text)
n_tokens = Nx.size(input_ids)
n_train = round(n_tokens * 0.9)
n_val = n_tokens - n_train

train_data =
  for {input_key, tokenized_values} <- tokenized_text, into: %{} do
    {input_key, Nx.slice_along_axis(tokenized_values, 0, n_train, axis: -1)}
  end

test_data =
  for {input_key, tokenized_values} <- tokenized_text, into: %{} do
    {input_key, Nx.slice_along_axis(tokenized_values, n_train, n_val, axis: -1)}
  end
```

<!-- livebook:{"output":true} -->

```
%{
  "attention_mask" => #Nx.Tensor<
    u32[1][33802]
    EXLA.Backend<host:0, 0.3594301091.1681522703.216578>
    [
      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]
    ]
  >,
  "input_ids" => #Nx.Tensor<
    u32[1][33802]
    EXLA.Backend<host:0, 0.3594301091.1681522703.216579>
    [
      [18495, 389, 925, 284, 6842, 11, 290, 523, 389, 345, 13, 198, 198, 42, 12599, 1503, 28893, 25, 198, 2949, 884, 474, 671, 355, 345, 11, 611, 502, 345, 1612, 13, 198, 198, 47731, 49, 52, 3398, 9399, 25, 198, 2348, 292, 0, 922, 16693, 11, 314, 481, ...]
    ]
  >,
  "token_type_ids" => #Nx.Tensor<
    u32[1][33802]
    EXLA.Backend<host:0, 0.3594301091.1681522703.216580>
    [
      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]
    ]
  >
}
```

```elixir
defmodule DataStream do
  def get_batch_stream(%{"input_ids" => input_ids} = data, batch_size, block_size, opts \\ []) do
    seed = Keyword.get(opts, :seed, 1337)

    Stream.resource(
      # initialization function
      fn ->
        Nx.Random.key(seed)
      end,
      # generation function
      fn key ->
        {_b, t} = Nx.shape(input_ids)

        data =
          for {k, v} <- data, into: %{} do
            {k, Nx.reshape(v, {t})}
          end

        # ix = list of random starting indices
        {ix, new_key} =
          Nx.Random.randint(key, 0, t - block_size, shape: {batch_size}, type: :u32)

        ix = Nx.to_list(ix)

        # x is map of sliced tensors
        x =
          for {k, tensor} <- data, into: %{} do
            batch_slice =
              ix
              |> Enum.map(fn i -> Nx.slice_along_axis(tensor, i, block_size, axis: -1) end)
              |> Nx.stack()

            {k, batch_slice}
          end

        # y represents all the predicted next tokens (input_ids shifted by 1) 
        y =
          ix
          |> Enum.map(fn i ->
            data["input_ids"] |> Nx.slice_along_axis(i + 1, block_size, axis: -1)
          end)
          |> Nx.stack()
          |> Nx.flatten()

        out_data = {x, y}

        {[out_data], new_key}
      end,
      fn _ -> :ok end
    )
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, DataStream, <<70, 79, 82, 49, 0, 0, 16, ...>>, {:get_batch_stream, 4}}
```

You can see what a single batch looks like by grabbing 1 from the stream:

```elixir
train_batch_stream = DataStream.get_batch_stream(train_data, batch_size, sequence_length)
test_batch_stream = DataStream.get_batch_stream(test_data, batch_size, sequence_length)

[{x, y}] = train_batch_stream |> Enum.take(1)
[{x_val, y_val}] = test_batch_stream |> Enum.take(1)

Bumblebee.Tokenizer.decode(tokenizer, x["input_ids"]) |> IO.inspect()
IO.puts("=====")
Bumblebee.Tokenizer.decode(tokenizer, y) |> IO.inspect()
```

<!-- livebook:{"output":true} -->

```
[" set down your honourable load,\nIf honour may be shrouded in a hearse,\nWhilst I awhile obsequiously lament\nThe untimely fall of virtuous Lancaster.\nPoor key-cold figure of a holy king!\nPale ashes of the house of Lancaster!\nThou bloodless remnant",
 "Post:\nAy, gracious sovereign; they are so link'd in\nfriendship\nThat young Prince Edward marries Warwick's daughter.\n\nCLARENCE:\nBelike the elder; Clarence will have the younger.\nNow, brother king, farewell, and sit you fast,\nFor I will hence",
 "And here he comes.\nAll hail, my sovereign liege!\n\nKING RICHARD III:\nKind Tyrrel, am I happy in thy news?\n\nTYRREL:\nIf to have done the thing you gave in charge\nBeget your happiness, be happy then,\nFor it",
 "Thou frantic woman, what dost thou make here?\nShall thy old dugs once more a traitor rear?\n\nDUCHESS OF YORK:\nSweet York, be patient. Hear me, gentle liege.\n\nHENRY BOLINGBROKE:\nRise up"]
=====
" down your honourable load,\nIf honour may be shrouded in a hearse,\nWhilst I awhile obsequiously lament\nThe untimely fall of virtuous Lancaster.\nPoor key-cold figure of a holy king!\nPale ashes of the house of Lancaster!\nThou bloodless remnant of:\nAy, gracious sovereign; they are so link'd in\nfriendship\nThat young Prince Edward marries Warwick's daughter.\n\nCLARENCE:\nBelike the elder; Clarence will have the younger.\nNow, brother king, farewell, and sit you fast,\nFor I will hence to here he comes.\nAll hail, my sovereign liege!\n\nKING RICHARD III:\nKind Tyrrel, am I happy in thy news?\n\nTYRREL:\nIf to have done the thing you gave in charge\nBeget your happiness, be happy then,\nFor it isou frantic woman, what dost thou make here?\nShall thy old dugs once more a traitor rear?\n\nDUCHESS OF YORK:\nSweet York, be patient. Hear me, gentle liege.\n\nHENRY BOLINGBROKE:\nRise up,"
```

<!-- livebook:{"output":true} -->

```
" down your honourable load,\nIf honour may be shrouded in a hearse,\nWhilst I awhile obsequiously lament\nThe untimely fall of virtuous Lancaster.\nPoor key-cold figure of a holy king!\nPale ashes of the house of Lancaster!\nThou bloodless remnant of:\nAy, gracious sovereign; they are so link'd in\nfriendship\nThat young Prince Edward marries Warwick's daughter.\n\nCLARENCE:\nBelike the elder; Clarence will have the younger.\nNow, brother king, farewell, and sit you fast,\nFor I will hence to here he comes.\nAll hail, my sovereign liege!\n\nKING RICHARD III:\nKind Tyrrel, am I happy in thy news?\n\nTYRREL:\nIf to have done the thing you gave in charge\nBeget your happiness, be happy then,\nFor it isou frantic woman, what dost thou make here?\nShall thy old dugs once more a traitor rear?\n\nDUCHESS OF YORK:\nSweet York, be patient. Hear me, gentle liege.\n\nHENRY BOLINGBROKE:\nRise up,"
```

## Train the model

Now we can go about training the model! First, we need to extract the Axon model and parameters from the Bumblebee model map:

```elixir
%{model: model, params: params} = model

model
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"attention_head_mask" => {12, 12}, "attention_mask" => {nil, nil}, "cache" => nil, "input_embeddings" => {nil, nil, 768}, "input_ids" => {nil, nil}, "position_ids" => {nil, nil}}
  outputs: "container_37"
  nodes: 859
>
```

The Axon model actually outputs a map with `:logits`, `:hidden_states`, and `:attentions`. You can see this by using `Axon.get_output_shape/2` with an input. This method symbolically executes the graph and gets the resulting shapes:

```elixir
[{input, _}] = Enum.take(train_batch_stream, 1)
Axon.get_output_shape(model, input)
```

<!-- livebook:{"output":true} -->

```
%{
  cache: #Axon.None<...>,
  logits: {4, 64, 50257},
  cross_attentions: #Axon.None<...>,
  hidden_states: #Axon.None<...>,
  attentions: #Axon.None<...>
}
```

For training, we only care about the `:logits` key, so we'll extract that by attaching an `Axon.nx/2` layer to the model:

```elixir
logits_model = Axon.nx(model, & &1.logits)
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"attention_head_mask" => {12, 12}, "attention_mask" => {nil, nil}, "input_ids" => {nil, nil}, "position_ids" => {nil, nil}, "token_type_ids" => {nil, nil}}
  outputs: "nx_0"
  nodes: 791
>
```

Now we can declare our training loop. You can construct Axon training loops using the `Axon.Loop.trainer/3` factory method with a model, loss function, and optimizer. We'll also adjust the log-settings to more frequently log metrics to standard out:

```elixir
loss =
  &Axon.Losses.categorical_cross_entropy(&1, &2,
    reduction: :mean,
    from_logits: true,
    sparse: true
  )

optimizer = Polaris.Optimizers.adam(learning_rate: 5.0e-5)

loop = Axon.Loop.trainer(logits_model, loss, optimizer, log: 1)
```

<!-- livebook:{"output":true} -->

```
#Axon.Loop<
  metrics: %{
    "loss" => {#Function<11.3813108/3 in Axon.Metrics.running_average/1>,
     #Function<41.3316493/2 in :erl_eval.expr/6>}
  },
  handlers: %{
    completed: [],
    epoch_completed: [
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<6.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    epoch_halted: [],
    epoch_started: [],
    halted: [],
    iteration_completed: [
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<64.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    iteration_started: [],
    started: []
  },
  ...
>
```

The call to trainer just returns a data structure. In Axon, we manipulate this data structure to control different parts of the loop. For example, you can attach metrics:

```elixir
accuracy = &Axon.Metrics.accuracy(&1, &2, from_logits: true, sparse: true)

loop = Axon.Loop.metric(loop, accuracy, "accuracy")
```

<!-- livebook:{"output":true} -->

```
#Axon.Loop<
  metrics: %{
    "accuracy" => {#Function<11.3813108/3 in Axon.Metrics.running_average/1>,
     #Function<41.3316493/2 in :erl_eval.expr/6>},
    "loss" => {#Function<11.3813108/3 in Axon.Metrics.running_average/1>,
     #Function<41.3316493/2 in :erl_eval.expr/6>}
  },
  handlers: %{
    completed: [],
    epoch_completed: [
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<6.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    epoch_halted: [],
    epoch_started: [],
    halted: [],
    iteration_completed: [
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<64.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    iteration_started: [],
    started: []
  },
  ...
>
```

And you can attach event handlers to do certain things, such as serialize the loop state at regular intervals so you don't lose your progress:

```elixir
loop = Axon.Loop.checkpoint(loop, event: :epoch_completed)
```

<!-- livebook:{"output":true} -->

```
#Axon.Loop<
  metrics: %{
    "accuracy" => {#Function<11.3813108/3 in Axon.Metrics.running_average/1>,
     #Function<41.3316493/2 in :erl_eval.expr/6>},
    "loss" => {#Function<11.3813108/3 in Axon.Metrics.running_average/1>,
     #Function<41.3316493/2 in :erl_eval.expr/6>}
  },
  handlers: %{
    completed: [],
    epoch_completed: [
      {#Function<17.14409478/1 in Axon.Loop.checkpoint/2>,
       #Function<6.14409478/2 in Axon.Loop.build_filter_fn/1>},
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<6.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    epoch_halted: [],
    epoch_started: [],
    halted: [],
    iteration_completed: [
      {#Function<27.14409478/1 in Axon.Loop.log/3>,
       #Function<64.14409478/2 in Axon.Loop.build_filter_fn/1>}
    ],
    iteration_started: [],
    started: []
  },
  ...
>
```

To run the loop, you just need to call `Axon.Loop.run/4`. `Axon.Loop.run/4` takes a loop, input data, and any initial state (in this case initial parameters). You can kind of think of `Axon.Loop.run/4` as an `Enum.reduce/3`. It takes data, an accumulator, and a function - which map to `Loop.run/4` input data, initial state, and the actual loop data structure.

You'll commonly see loops written out in long chains using Elixir's `|>` operator, like this:

```elixir
trained_model_state =
  logits_model
  |> Axon.Loop.trainer(loss, optimizer, log: 1)
  |> Axon.Loop.metric(accuracy, "accuracy")
  |> Axon.Loop.checkpoint(event: :epoch_completed)
  |> Axon.Loop.run(train_data, params, epochs: 3, compiler: EXLA, strict?: false)

:ok
```

<!-- livebook:{"output":true} -->

```

02:46:02.170 [debug] Forwarding options: [compiler: EXLA] to JIT compiler
Epoch: 0, Batch: 249, accuracy: 0.3462500 loss: 1.2216607
Epoch: 1, Batch: 249, accuracy: 0.5186251 loss: 1.0558304
Epoch: 2, Batch: 249, accuracy: 0.6236249 loss: 0.9317472
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Evaluating the model

The training loop returns the final model state after training over your dataset for the given number of epochs. Axon uses the same `Axon.Loop` API to create evaluation loops as well. You can create one with the `Axon.Loop.evaluator/1` factory, instrument it with metrics, and run it on your data with your trained model state:

```elixir
logits_model
|> Axon.Loop.evaluator()
|> Axon.Loop.metric(accuracy, "accuracy")
|> Axon.Loop.run(test_data, trained_model_state, compiler: EXLA)
```

<!-- livebook:{"output":true} -->

```
Batch: 49, accuracy: 0.3675000
```

<!-- livebook:{"output":true} -->

```
%{
  0 => %{
    "accuracy" => #Nx.Tensor<
      f32
      EXLA.Backend<host:0, 0.446408219.3911319572.169449>
      0.36750003695487976
    >
  }
}
```
