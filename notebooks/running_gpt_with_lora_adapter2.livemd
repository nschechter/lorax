<!-- livebook:{"persist_outputs":true} -->

# Running GPT2 with LoRA parameters

```elixir
Mix.install([
  {:bumblebee, "~> 0.4.2"},
  {:axon, "~> 0.6.0"},
  {:nx, "~> 0.6.1"},
  {:exla, "~> 0.6.1"},
  {:explorer, "~> 0.7.0"},
  {:lorax, git: "https://github.com/spawnfest/lorax.git"},
  # {:lorax, path: "/Users/ted/CS/elixir/lorax"},
  {:req, "~> 0.4.0"},
  {:kino, "~> 0.11.0"}
])

Nx.default_backend(EXLA.Backend)
```

## Mimicking the Elixirforum Help Section

One great benefit to LoRA is the file size of the fine-tuned parameters. What we can do is load one of the parameters named `elixirforum-help-section.lorax` and upload it to the Kino input down below.

The other notebook in this package fine-tuned the GPT2 model to learn the associations typically found in an Elixirforum thread.

The average computer should be able to run the GPT2 inference without much problems. You'll see that it generates some random thread you may find in the help section.

## Load model

```elixir
{:ok, spec} = Bumblebee.load_spec({:hf, "gpt2"})
{:ok, model} = Bumblebee.load_model({:hf, "gpt2"}, spec: spec)
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "gpt2"})
{:ok, generation_config} = Bumblebee.load_generation_config({:hf, "gpt2"})

%{model: model, params: gpt2_params} = model

:ok
```

<!-- livebook:{"output":true} -->

```

18:42:59.006 [info] TfrtCpuClient created.

```

<!-- livebook:{"output":true} -->

```
:ok
```

## Upload Params

```elixir
input = Kino.Input.file("Lorax Params")
```

## Load Param File

Although we've loaded the LoRA params, we still need the original parameters (the extremely large ones). We'll merge the parameters into one single mapping of layers -> tensor values, and Axon will be able to run it

```elixir
lora_params = Lorax.Params.kino_load_file!(input)
merged_params = Lorax.Params.merge_params(lora_params, gpt2_params)
```

<!-- livebook:{"output":true} -->

```
%{
  "decoder.blocks.7.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220002>
      [-0.0015067235799506307, 0.011825020425021648, -0.015962932258844376, -0.009843949228525162, 0.017166582867503166, -0.0023309593088924885, 0.01716618798673153, -0.01785222440958023, 0.02480374090373516, -0.04544716328382492, -0.04233347252011299, 0.19252289831638336, 0.023084215819835663, 0.010606026276946068, 0.020862935110926628, -0.014164811000227928, 0.04407064616680145, -0.001367615768685937, 0.03417485952377319, 0.0010759946890175343, 0.020503727719187737, -0.018043607473373413, -0.00980320293456316, 0.028919916599988937, -0.003041631542146206, -0.041081931442022324, -0.030980169773101807, 0.0037019671872258186, 0.009434754960238934, -0.004209163598716259, 0.0016339614521712065, 0.02209661342203617, -0.014821838587522507, -0.02030492015182972, 0.03273279219865799, -0.04265918210148811, 0.00601721927523613, 0.00928163155913353, -0.028216741979122162, -0.007809154689311981, -0.03414953500032425, -0.011486138217151165, -0.006398558616638184, -0.014157279394567013, 0.010680632665753365, -0.06726251542568207, -0.0386282317340374, 0.007625897414982319, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220001>
      [
        [0.021402638405561447, 0.050967343151569366, 0.04545518010854721, -0.0109089445322752, -0.04193441942334175, -0.023326827213168144, 0.09840112924575806, 0.10209610313177109, 0.05283593386411667, 0.034540046006441116, 0.05829596519470215, -0.1514427661895752, 0.0445757620036602, -0.014143920503556728, 0.009306855499744415, 0.07754021883010864, 0.11058628559112549, -0.11392591893672943, 0.05147108808159828, 0.014121315442025661, 0.0954991802573204, 0.032277483493089676, 0.09881661087274551, 0.13257817924022675, -0.02898217923939228, -0.08612077683210373, -0.10402683913707733, 0.032209958881139755, 0.07464122027158737, -0.04770876094698906, -0.12873615324497223, 0.04697330668568611, -0.04240507632493973, -0.058180730789899826, 9.088746155612171e-4, 0.05110365152359009, 0.20511674880981445, -0.020681431517004967, -0.01085528265684843, -0.1648135483264923, 0.038136307150125504, -0.01178289670497179, -0.005067809019237757, -0.11831668764352798, 0.08509404212236404, -0.008230645209550858, 0.08802532404661179, ...],
        ...
      ]
    >
  },
  "decoder.blocks.0.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220055>
      [0.045023269951343536, 0.03226305544376373, -0.08854541927576065, -0.008162474259734154, 0.11771649867296219, -0.2388763129711151, -0.0758744403719902, 0.029564158990979195, 0.04648246616125107, -0.0027773359324783087, -0.0038145091384649277, 0.020842736586928368, 0.009267736226320267, 0.03588847070932388, -0.1409134566783905, 0.06138546019792557, -0.06896162778139114, -0.012951075099408627, 0.06189567223191261, -0.017779534682631493, 0.021359939128160477, -0.05501718819141388, 0.02197490818798542, 0.0011829776922240853, 0.04943571239709854, 0.04192988574504852, 0.07189816981554031, -0.020239252597093582, 0.06509828567504883, 0.10963835567235947, 0.04001740366220474, 0.03582198917865753, 0.06442175805568695, -0.031552474945783615, 0.020920773968100548, -0.05902986228466034, 0.019308188930153847, -0.03758474066853523, 0.04784710705280304, 0.1294996589422226, 0.0656597912311554, 0.16015131771564484, 0.0036071811337023973, 0.013143805786967278, 0.08715710043907166, -0.05141830816864967, 0.10630246251821518, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219942>
      [
        [-0.10660640895366669, 0.1527840495109558, 0.03310481086373329, 0.023700203746557236, 0.02993733063340187, -0.07244370877742767, -0.55028235912323, 0.10002829134464264, 0.10845957696437836, -0.06486132740974426, -0.050516318529844284, -0.04687585309147835, -0.019445782527327538, -0.031208522617816925, -0.1474572867155075, 0.00985053088515997, 0.14931969344615936, 0.07806558161973953, -9.190309210680425e-4, 0.23059925436973572, -0.021436616778373718, 0.04766186699271202, -0.07279295474290848, 0.06045343354344368, 0.013344594277441502, 0.16240741312503815, 0.11852358281612396, -0.02879641018807888, 0.05925842374563217, 0.12395480275154114, -0.09108705073595047, -0.01235614251345396, 0.03735384717583656, -0.022464079782366753, -0.045593757182359695, -0.27166813611984253, -0.04527653008699417, 0.03668154403567314, 0.08654572069644928, 0.023413583636283875, -0.08427132666110992, -0.03452301397919655, 0.03188594430685043, -0.043258294463157654, -0.05696522071957588, 0.018179383128881454, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220035>
      [0.020700350403785706, -0.26381751894950867, -0.1094379648566246, 0.2875203490257263, 0.2774174213409424, 0.04697851091623306, 0.062320489436388016, 0.025348320603370667, -0.1447840929031372, 0.23507045209407806, -0.22111418843269348, -0.04685695096850395, 0.04695908725261688, -0.08256081491708755, 0.049968790262937546, 0.0957123190164566, 0.008569050580263138, 0.36251145601272583, 0.026079699397087097, 0.14226137101650238, 0.30309706926345825, -0.051855895668268204, -0.041972529143095016, 0.045346442610025406, 0.09475845843553543, 0.03463638201355934, 0.11646518856287003, -0.13341329991817474, 0.10428164899349213, -0.16626955568790436, 0.008327489718794823, 0.11973997205495834, 0.1891246736049652, 0.27689802646636963, 0.07897856086492538, 0.2317073494195938, 3.121290064882487e-4, 0.014473449438810349, -0.22102972865104675, -0.024565676227211952, 0.0030907581094652414, -0.10433603823184967, 0.2853952944278717, 0.022545315325260162, 0.10485214740037918, 0.2518227994441986, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219934>
      [
        [-0.013124971650540829, -0.06660282611846924, -0.0697135180234909, -0.030710719525814056, 0.042854610830545425, 0.008408921770751476, -0.03381262347102165, 0.06493787467479706, -0.03271748125553131, 0.12311036139726639, 0.1337415724992752, 0.10496947169303894, 0.0691475197672844, 0.015230960212647915, -0.07322822511196136, -0.05089348554611206, 0.09375757724046707, -0.13991476595401764, -0.05577455088496208, 0.04202907159924507, -0.028392035514116287, -0.07780732214450836, -0.05117521435022354, -0.010147273540496826, -0.09198098629713058, -0.15541940927505493, -0.09189142286777496, 0.04543245583772659, 0.05888330563902855, 0.007717895321547985, -0.055146679282188416, -0.10239534080028534, 0.01507049985229969, -0.01887754164636135, -0.06463737785816193, -0.10168686509132385, -0.04603245481848717, -0.03781770542263985, 0.08949298411607742, -0.014968409202992916, 0.01719915308058262, 0.01886896975338459, 0.040570300072431564, 0.052193399518728256, -0.04610079526901245, ...],
        ...
      ]
    >
  },
  "decoder.blocks.6.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219981>
      [0.045025456696748734, 0.009542928077280521, 0.016986900940537453, 0.013239625841379166, 0.022165829315781593, -0.02997750975191593, -0.05318791791796684, 0.030291369184851646, 0.021082192659378052, 0.014847509562969208, -1.6169920513675606e-7, 0.0210530087351799, 0.056806933134794235, 0.009754392318427563, -0.06860926002264023, 0.03423593193292618, -0.02938588336110115, 0.015446092002093792, 0.010956122539937496, -0.02942276932299137, 0.03855720907449722, 0.01702086068689823, -0.005053986329585314, 0.017972847446799278, 0.014045481570065022, 0.021662695333361626, 0.02321026474237442, 0.04095667600631714, 0.0021895733661949635, 0.016517585143446922, -0.004257701337337494, -0.013539420440793037, -0.01618128828704357, -0.007974829524755478, -0.004954650532454252, -0.03999199718236923, -0.02632948011159897, -0.01814391277730465, 0.004013486206531525, 0.007407412398606539, 0.001718125189654529, 0.019525639712810516, 0.0014584340387955308, 0.022858886048197746, 5.235132412053645e-4, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219982>
      [0.25878557562828064, 0.2482416182756424, 0.27244293689727783, 0.2566904127597809, 0.2704152762889862, 0.2627618908882141, 0.29589709639549255, 0.18097728490829468, 0.2705056071281433, 0.2587742209434509, 0.26464471220970154, 0.2627030909061432, 0.2763660252094269, 0.26602861285209656, 0.2792193293571472, 0.262694776058197, 0.2730119526386261, 0.2646535038948059, 0.24892735481262207, 0.24463066458702087, 0.2625494599342346, 0.2543585002422333, 0.2724483907222748, 0.23977135121822357, 0.2607770562171936, 0.25832539796829224, 0.2607426345348358, 0.2576335072517395, 0.2551948130130768, 0.2608013451099396, 0.2707134485244751, 0.2568177878856659, 0.2546869218349457, 0.24516521394252777, 0.2724584937095642, 0.27050986886024475, 0.22996947169303894, 0.2724611461162567, 0.2426939308643341, 0.24848425388336182, 0.2568362355232239, 0.2662496268749237, 0.2592116594314575, 0.2666124701499939, ...]
    >
  },
  "decoder.blocks.11.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219895>
      [0.105723537504673, 0.11879222095012665, 0.006737913005053997, 0.05425174906849861, -0.020953308790922165, 0.00772686256095767, 0.05538606271147728, 0.05174220725893974, 0.02458597719669342, 0.05650372430682182, 0.07260715216398239, 0.015075696632266045, 0.07118107378482819, -0.02622274123132229, -0.004771863576024771, 0.13389313220977783, -0.04042479023337364, -0.09605908393859863, 0.05143333226442337, -0.0777275338768959, -0.038933414965867996, -0.01103443093597889, 0.22768071293830872, -0.051514096558094025, -0.09891602396965027, 0.0014073842903599143, -0.04144133999943733, 0.034522294998168945, -0.009654851630330086, 0.005805726628750563, 0.04466322436928749, -0.047319527715444565, -0.009854177013039589, 0.01743702031672001, 0.1440771073102951, -0.12892374396324158, 0.18401136994361877, -0.017713360488414764, -0.21362674236297607, 0.06416985392570496, 0.07322429120540619, 0.08671480417251587, 0.0764789879322052, 0.057795871049165726, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219883>
      [
        [0.06805934756994247, 0.09200220555067062, -0.03102017380297184, -0.20520317554473877, 0.06265048682689667, 0.17043784260749817, 0.037615444511175156, -0.24390925467014313, -0.06584632396697998, -0.36999693512916565, 0.19122055172920227, 0.07945571839809418, 0.008697953075170517, 0.19716542959213257, 0.17863412201404572, -0.01731661520898342, -0.3208216726779938, 0.21022184193134308, 0.080193892121315, 0.07145563513040543, -0.24923168122768402, -0.050284698605537415, -0.2518293559551239, 0.2810163199901581, -0.28573331236839294, 0.12340781837701797, -0.0859503522515297, 0.08418150991201401, -0.03493265062570572, 0.13855530321598053, -0.241315558552742, 0.15032462775707245, -0.25630655884742737, -0.03904435783624649, 0.0643249899148941, 0.26296404004096985, 0.44665995240211487, -0.001308600651100278, 0.16780276596546173, -0.14047899842262268, -0.03252283111214638, -0.3422131836414337, -0.15174603462219238, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220014>
      [0.01611318439245224, 1.9620818784460425e-4, -0.033592935651540756, -0.014356587082147598, -0.010978053323924541, -0.005805983208119869, 0.0022555338218808174, 0.007051336579024792, 0.014428694732487202, -0.019858360290527344, -0.058242809027433395, -0.027789494022727013, -0.021741623058915138, 0.02190697006881237, -0.0035076746717095375, 0.002187394769862294, -0.022275205701589584, -0.009000930935144424, 0.0014367415569722652, -0.02442094311118126, -0.02785932831466198, -0.027073200792074203, 0.009673072025179863, -0.01975858025252819, -0.006040024105459452, -0.005454181227833033, -0.012051430530846119, 0.007628345862030983, -0.0019122350495308638, -0.031798556447029114, -0.03979314863681793, 0.0018334127962589264, 5.315942107699811e-4, -0.02355266362428665, 0.019198285415768623, -0.01209992729127407, 0.011508915573358536, 0.033759962767362595, 0.003140085143968463, -0.43169018626213074, -0.004638292361050844, 0.029909860342741013, -0.026687445119023323, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220013>
      [
        [0.02292151376605034, 0.0338389091193676, -0.047796934843063354, 0.09596998244524002, 0.045752089470624924, -0.030947083607316017, -0.06484285742044449, -0.021927157416939735, 0.08957719802856445, -0.06526286900043488, 0.048477549105882645, -0.007700455840677023, -0.09442861378192902, -0.13685542345046997, -0.10288318246603012, -0.09903551638126373, 0.17210477590560913, -0.014380788430571556, -0.081391841173172, -0.09592964500188828, -0.20048144459724426, -0.014696544967591763, 0.08353224396705627, 0.10173220932483673, -0.05892166867852211, -0.0928846076130867, 0.07746145129203796, 0.12805286049842834, -0.14344947040081024, 0.12638360261917114, 0.03233393654227257, 0.044042039662599564, -0.0408482551574707, -0.08512827754020691, 0.17795124650001526, -0.18981613218784332, -0.04125617817044258, 0.018192069604992867, 0.19313742220401764, -0.08462966978549957, 0.13086268305778503, 0.18106544017791748, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220022>
      [-0.014248297549784184, -0.240375816822052, -0.018260201439261436, 0.11563233286142349, 0.18061132729053497, 0.04692136496305466, -0.009259623475372791, -0.05987045168876648, -0.10537739843130112, 0.10199987143278122, -0.10119312256574631, 0.054955385625362396, 0.08877909928560257, -0.034204259514808655, -0.030978145077824593, -0.14948132634162903, 0.013923843391239643, 0.22173760831356049, -0.044307757169008255, 0.11177702248096466, 0.25232768058776855, -0.011090553365647793, -0.02736673317849636, -0.05436551198363304, 0.035498980432748795, 0.06144917383790016, 0.10569152981042862, -0.06352245807647705, -0.014585292898118496, -0.08527898788452148, 0.06996647268533707, 0.15424810349941254, 0.2633742094039917, 0.07891955971717834, 0.10157502442598343, 0.15565523505210876, -0.05072539672255516, -0.015324545092880726, -0.13633786141872406, -0.0920839011669159, 0.02864094078540802, -0.1776469349861145, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219929>
      [
        [0.06602837890386581, -0.005861711222678423, -0.03592158108949661, -0.17321670055389404, -0.040567655116319656, -0.12914139032363892, -0.039053335785865784, 0.055556997656822205, -0.03793487325310707, -0.040671199560165405, -0.10253544896841049, -0.010256040841341019, -0.046774111688137054, -0.04418528825044632, -0.19765710830688477, 0.03096650168299675, 0.04684501513838768, -0.0827573910355568, 0.06590650230646133, 0.0626329854130745, -0.03907793387770653, -0.08920115977525711, 0.12399065494537354, 0.11888366937637329, 0.04018740355968475, -0.06762197613716125, -0.007350870408117771, 0.0679413229227066, -0.05717582628130913, -0.006823679432272911, -0.037478987127542496, -0.022401340305805206, -0.026354540139436722, -0.16326986253261566, 0.026277117431163788, -0.04454047232866287, -0.19500863552093506, -0.10626175254583359, 0.09581570327281952, 9.76486480794847e-4, 0.03719896450638771, ...],
        ...
      ]
    >
  },
  "decoder.blocks.7.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219964>
      [0.003023461438715458, -0.0034503634087741375, -0.05022025108337402, 0.1445682793855667, -0.061383385211229324, -0.18525145947933197, 0.05382299795746803, 0.09621239453554153, 0.22644995152950287, 0.13868243992328644, -0.10454718768596649, -0.0445207841694355, 0.17207269370555878, 0.13456888496875763, -0.08831684291362762, -0.02446838468313217, -0.031328264623880386, 0.12339051067829132, 0.055783338844776154, -0.06627967208623886, 0.12010461091995239, -0.005991296377032995, -0.012475112453103065, -0.0091325668618083, -0.12514269351959229, -0.03106873109936714, -0.07901277393102646, 0.10679206997156143, 0.023926347494125366, 0.19130189716815948, -0.07669995725154877, -3.717075742315501e-4, -0.022119715809822083, -0.12196514755487442, -0.006166365463286638, -0.003968436270952225, 0.17010942101478577, -0.08083401620388031, -0.06381057947874069, 0.012830626219511032, 0.008812617510557175, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219907>
      [
        [0.02272615395486355, -0.03426380455493927, 0.10830746591091156, -0.0698532909154892, -0.04444117844104767, -0.1163613572716713, -0.10804831981658936, 0.027915891259908676, -0.06091436743736267, 0.11493780463933945, -0.12441886961460114, -0.12758924067020416, -0.08719192445278168, -0.08544804900884628, 0.01870325393974781, 0.06337859481573105, -0.05752550810575485, 0.08484397083520889, 0.10050169378519058, -8.142094011418521e-4, 0.04208269715309143, -0.0010115094482898712, 0.016743609681725502, -0.14341019093990326, -0.11040765047073364, -0.015847202390432358, 0.06745976209640503, 0.028722982853651047, 0.034336477518081665, -0.02375819906592369, -0.04028434678912163, 0.04014326259493828, -0.0828038826584816, 0.04731905460357666, -0.030171439051628113, 0.007872296497225761, -0.0554569847881794, -0.057010941207408905, -0.03682035207748413, 0.003613386768847704, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219976>
      [3.5320030292496085e-4, -0.02352035790681839, 0.03579441457986832, -0.00819009356200695, -0.013341247104108334, 0.22570614516735077, 0.014364250004291534, 0.01957814209163189, -0.0029258071444928646, -0.005615453235805035, 0.006173497997224331, 0.03394452482461929, 0.04145542159676552, 0.02271554060280323, 0.027301738038659096, 0.023053526878356934, -0.030637608841061592, 0.0011183557799085975, 0.009655783884227276, -0.0031652075704187155, 0.004611491225659847, -8.690875256434083e-4, -0.0060260300524532795, -0.009716540575027466, 0.014348393306136131, -0.010869566351175308, -0.015734069049358368, 0.02538462169468403, -0.02972058765590191, -5.710391560569406e-4, 9.462513262405992e-4, 0.022110195830464363, 0.004091514740139246, 9.700193768367171e-4, 0.009012877009809017, -0.013626644387841225, 0.38099005818367004, 0.01451069489121437, -0.023601410910487175, 0.018054811283946037, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219975>
      [
        [-0.05810696259140968, 0.06249383091926575, -0.16588400304317474, 0.09654977917671204, 0.09147700667381287, 0.048064541071653366, -0.09367276728153229, 0.014363005757331848, 0.10144679248332977, 0.0233471617102623, 0.006492226850241423, 0.024173308163881302, -0.08379942923784256, 0.035400889813899994, 0.011924143880605698, 0.06395914405584335, -0.025091668590903282, 0.23154862225055695, 0.04634566977620125, -0.03464064002037048, 0.019783668220043182, -0.09660620987415314, -0.08186054974794388, -0.18600694835186005, -0.11908779293298721, 0.21912004053592682, -0.09747152775526047, -0.010526714846491814, -0.015264575369656086, -0.12838749587535858, 0.061404332518577576, -0.07993568480014801, -0.016672959551215172, 0.007367889396846294, 0.06115908920764923, -0.00501360883936286, -0.009648752398788929, -0.11571478843688965, 0.022876223549246788, ...],
        ...
      ]
    >
  },
  "dropout_28" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220432>
      [395490763, 1848537238]
    >
  },
  "decoder.blocks.2.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220029>
      [-0.0654396265745163, 0.10812345892190933, 0.04286130890250206, -0.2760961353778839, 0.08625604957342148, -0.2286910116672516, -0.04461458697915077, 7.275498937815428e-4, 0.10620112717151642, 0.10470309853553772, -0.08921228349208832, 0.07638224959373474, 0.1359548419713974, 0.011987983249127865, -0.13395175337791443, -0.012165425345301628, -0.02094808965921402, -0.24327068030834198, 0.19702652096748352, -0.11469811946153641, 0.06039329245686531, -0.0885312408208847, 0.03518642485141754, -0.032149139791727066, 0.051021404564380646, 0.05498753488063812, 0.08870009332895279, 0.06739293038845062, 0.0710294097661972, 0.13408461213111877, 0.029301894828677177, -0.00930361170321703, 0.025734776630997658, -0.24615506827831268, -0.08097236603498459, -0.06227843463420868, 0.005404133815318346, -0.11257304251194, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219932>
      [
        [-0.02398330718278885, -0.20910729467868805, -0.029130421578884125, -0.014159053564071655, 0.12113775312900543, -0.02065293677151203, -0.11999223381280899, -0.269276887178421, 7.631823536939919e-4, 0.04650465399026871, -0.045628879219293594, -0.12281503528356552, 0.02982284128665924, 0.06332483142614365, -0.05124947428703308, 0.004213565960526466, 0.05839945375919342, 0.1387341022491455, 0.039438631385564804, -0.07732643932104111, 0.11901428550481796, -0.0635095089673996, 0.06668639183044434, 0.15541701018810272, -0.04893676936626434, -0.13186554610729218, 0.03706846386194229, 0.08605990558862686, -0.20225566625595093, -0.11350183933973312, 0.06946399807929993, -6.101589533500373e-4, -0.0847146287560463, -0.04157274588942528, 0.0049753207713365555, -0.015184903517365456, -0.16200494766235352, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219974>
      [-0.09291772544384003, -0.04217880591750145, -0.020356424152851105, 0.04034513235092163, -0.013874712400138378, -0.11893210560083389, -0.05924098193645477, -0.027365664020180702, 0.05266174301505089, 0.008417871780693531, -0.0861397385597229, -0.019344178959727287, -0.06396947801113129, 0.046350132673978806, 0.05676386505365372, -5.086865712655708e-6, 0.10372238606214523, -0.21678526699543, -0.09768351167440414, -0.009167345240712166, 0.08033648878335953, 0.0944061353802681, 0.08438227325677872, 0.22630733251571655, -0.14517657458782196, -0.007395234890282154, -0.13697558641433716, -0.059589944779872894, 0.1007838323712349, 0.006305344868451357, -0.16571001708507538, 0.011307205073535442, 0.07076525688171387, -0.007749190088361502, -0.03437885269522667, 0.11359181255102158, -0.0808584913611412, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219973>
      [
        [0.07191380113363266, -0.08377204835414886, 0.15178976953029633, 0.2953050136566162, 0.2969595789909363, 0.017495974898338318, -0.2548777759075165, -0.10065208375453949, 0.23874078691005707, -0.013963986188173294, 0.016722165048122406, 0.29725781083106995, -0.05463255196809769, -0.26017990708351135, 0.042508628219366074, 0.14374642074108124, 0.3041999638080597, 0.3108743131160736, -0.03671329841017723, -0.14828334748744965, -0.36135849356651306, 0.13315536081790924, 0.002669523935765028, 0.342965304851532, -0.00918323453515768, 0.5080976486206055, -0.33983874320983887, 0.34413501620292664, 0.34606099128723145, -0.09834522753953934, 0.09321682155132294, 0.027324317023158073, -0.029650583863258362, -0.07398593425750732, 0.28067755699157715, 0.086429163813591, ...],
        ...
      ]
    >
  },
  "decoder.blocks.5.self_attention_dropout" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220433>
      [395490763, 1846486734]
    >
  },
  "lora_11" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220154>
      [
        [-0.014504322782158852, -0.028570938855409622, -0.006773359142243862, -0.004604272078722715, -0.0044258469715714455, -0.01874873787164688, 0.03635276481509209, -8.18501110188663e-4, -0.0038995235227048397, 3.4298692480660975e-4, -0.01969740353524685, 0.02662605606019497, 0.001919346977956593, 0.02732773870229721, -9.714235202409327e-4, 0.012811053544282913, 0.0066286190412938595, 0.062174681574106216, -5.675600841641426e-4, 0.03442902863025665, -0.00834144651889801, -0.017401153221726418, 0.00815551821142435, 0.05371797829866409, 0.013413901440799236, 0.03099052421748638, -2.609079238027334e-4, -0.006266922224313021, -0.05724537372589111, -0.0032309023663401604, -0.029441360384225845, 0.007892071269452572, 0.027902081608772278, -0.027642978355288506, -0.01379694789648056, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220155>
      [
        [0.00402241013944149, -0.014116856269538403, 0.010655928403139114, -6.287224823608994e-4, 0.006045023910701275, -0.01084586326032877, -0.004452190361917019, -0.0017174467211589217],
        [0.004318640101701021, -0.01334917638450861, -0.004528483841568232, -0.012779751792550087, -5.708903772756457e-4, 0.00574902817606926, -0.008020827546715736, -0.008931140415370464],
        [-3.244186518713832e-4, 0.01654403656721115, 8.978134719654918e-4, -0.005040095187723637, 0.0012267186539247632, -0.003317925613373518, 0.007346923928707838, -0.0029196529649198055],
        [0.010620730929076672, 3.926882054656744e-4, 0.021095994859933853, -0.004451114684343338, 0.010225803591310978, -0.011770677752792835, -0.00888938456773758, -0.010210846550762653],
        [0.0032001633662730455, 0.028795544058084488, ...],
        ...
      ]
    >
  },
  "decoder.blocks.4.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220003>
      [-0.05897606164216995, 0.15732403099536896, -0.08401917666196823, -0.04356243461370468, -5.054371431469917e-4, -0.15412287414073944, -0.017296316102147102, 0.013370297849178314, 0.18167349696159363, 0.14976365864276886, -0.033649567514657974, -0.12340114265680313, 0.11543204635381699, 0.1179199367761612, -0.16670309007167816, 0.03197641670703888, -0.09725514054298401, -0.13734258711338043, 0.05221153423190117, -0.19777816534042358, -0.016869299113750458, -0.09240839630365372, -0.041709307581186295, 0.04953768476843834, -0.00948934257030487, -0.061544936150312424, 0.055073339492082596, 0.10132436454296112, 0.09503704309463501, 0.2767695188522339, -0.04178015887737274, -0.09199224412441254, -0.13981661200523376, -0.18259884417057037, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219922>
      [
        [-0.016589239239692688, 0.033356476575136185, -0.025944791734218597, -0.06458347290754318, -0.008617261424660683, -0.06050972640514374, 0.026528408750891685, -0.018711822107434273, 0.06334453076124191, -0.07016438990831375, -0.040474455803632736, -0.08900412917137146, -0.05415213108062744, 0.00924048200249672, -0.09849966317415237, 0.017269760370254517, 0.03402997925877571, -0.0723804235458374, 0.06440147757530212, 0.11115777492523193, -0.04786305129528046, 0.013474693521857262, 0.18404416739940643, -0.037795290350914, -0.1344190388917923, -0.041169364005327225, -0.02169586904346943, -0.09167039394378662, -0.047637294977903366, -0.010682673193514347, -0.017419137060642242, -0.09429912269115448, 0.09434686601161957, ...],
        ...
      ]
    >
  },
  "lora_31" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220156>
      [
        [-0.04538794979453087, -0.019891899079084396, -0.001344265416264534, 0.00610982533544302, -0.0660163089632988, 0.013794030994176865, -0.10852323472499847, 0.041646480560302734, 0.030162088572978973, -0.04966800659894943, 0.05143078789114952, -0.002960918704047799, -0.025800665840506554, 0.052689068019390106, -0.029850943014025688, 0.043031904846429825, -0.03700205311179161, 0.02588651329278946, 0.05760912969708443, 0.044124066829681396, -0.07582838088274002, 0.011411765590310097, 0.06009313091635704, 0.005793845281004906, -0.027521837502717972, 0.041255149990320206, -0.017239106819033623, -0.012291661463677883, 0.05942663550376892, 0.011019811034202576, 0.04523535445332527, -0.009922773577272892, 0.028887901455163956, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220157>
      [
        [-0.029237966984510422, -0.01019051019102335, -0.01172846183180809, 0.025228634476661682, -0.034481074661016464, -0.028466273099184036, -0.04492049664258957, -0.018407123163342476],
        [-0.015367770567536354, -0.01760847307741642, 0.004441031254827976, 0.003182100597769022, -0.009741186164319515, -0.020657580345869064, -0.028233787044882774, -0.021900402382016182],
        [0.00874341744929552, 0.019718537107110023, -0.008630959317088127, -0.003149911295622587, 0.013186798430979252, 0.00942433625459671, 0.020532099530100822, 0.011348722502589226],
        [-0.03797198086977005, -0.005194738507270813, -0.0231038685888052, 0.016080809757113457, -0.021916532889008522, -0.0028265470173209906, -0.0073684328235685825, 0.015968753024935722],
        ...
      ]
    >
  },
  "decoder.blocks.3.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220020>
      [0.02195732854306698, 0.035705193877220154, 0.04064951837062836, -0.025932105258107185, 0.014330854639410973, -0.039580412209033966, -0.1155749261379242, 0.028433658182621002, 0.030217133462429047, -0.007304288912564516, 0.002263169502839446, 0.048969969153404236, 0.05460219457745552, 0.004443574231117964, -0.07364215701818466, 0.029881520196795464, -0.01567690446972847, -0.01119413785636425, 0.010527174919843674, -0.014802615158259869, 0.0057569448836147785, -0.020488295704126358, 0.024373553693294525, -0.02502831257879734, 0.019044460728764534, 0.02883622609078884, 0.056766364723443985, 0.021289346739649773, 0.003697927575558424, 0.03079884685575962, 0.0382881686091423, 0.011968711391091347, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220021>
      [0.28222545981407166, 0.3131215572357178, 0.3034003973007202, 0.3393371105194092, 0.3154321610927582, 0.3309932053089142, 0.30264604091644287, 0.13720403611660004, 0.3059060573577881, 0.3251676857471466, 0.30764150619506836, 0.3226858973503113, 0.3249446153640747, 0.307298868894577, 0.28870701789855957, 0.3071806728839874, 0.2878659665584564, 0.3310546875, 0.29914483428001404, 0.2799876928329468, 0.350590318441391, 0.31099772453308105, 0.33301326632499695, 0.29779165983200073, 0.30957064032554626, 0.3072805106639862, 0.32713234424591064, 0.3132126033306122, 0.3168300688266754, 0.3154486119747162, 0.3116898834705353, ...]
    >
  },
  "lora_10" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220158>
      [
        [0.01776271127164364, -0.03328624367713928, -0.008142080157995224, 0.02633247710764408, -0.024939700961112976, -0.008835790678858757, 0.014763032086193562, -0.039563387632369995, -0.03999624028801918, -0.02929333783686161, -0.009100011549890041, -0.026120800524950027, -0.015618214383721352, -0.021900514140725136, 0.02514679729938507, -0.013382583856582642, 0.023554645478725433, -0.007840125821530819, -0.0310727059841156, -0.023849884048104286, -0.012197759002447128, -0.04241717606782913, 0.01463337428867817, 0.0417313426733017, -0.006003465037792921, 0.011097552254796028, -0.03507866710424423, 0.05313468351960182, -0.00744639802724123, -0.025410985574126244, -0.0018010002095252275, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220159>
      [
        [0.01700323261320591, 0.011676458641886711, 0.0032621892169117928, 0.008372674696147442, 0.005088106729090214, 0.027517113834619522, -0.0012730784947052598, -0.008239282295107841],
        [0.012898464687168598, -0.013268347829580307, 0.004585571587085724, -0.003284334670752287, 0.004224715288728476, -0.005137938540428877, -0.015610803849995136, -0.018546979874372482],
        [-0.007543373852968216, -0.03783304616808891, -0.025344323366880417, 0.0029034672770649195, 0.0019932484719902277, -0.028252389281988144, -0.011472041718661785, 0.015992797911167145],
        [0.02215428277850151, -0.01819206401705742, -0.01272007916122675, -0.021137401461601257, 0.004106440581381321, -0.017056327313184738, ...],
        ...
      ]
    >
  },
  "decoder.blocks.9.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220004>
      [-0.1255052387714386, 0.2206331193447113, 0.02155466005206108, -0.06883163750171661, -0.1582368165254593, -0.03266475349664688, 0.08761484920978546, -0.06262274831533432, 0.08110350370407104, -0.06443772464990616, -0.01988857425749302, -0.14905107021331787, 0.026666700839996338, 0.11045331507921219, 0.12034416198730469, -0.03482687100768089, -0.06882551312446594, -0.06385401636362076, 0.10434503108263016, -0.06925361603498459, 0.004499129019677639, 0.029036764055490494, 0.12643346190452576, 0.06261695176362991, 0.007506237365305424, -0.03166307136416435, 0.005090613849461079, 0.12981073558330536, 0.042653005570173264, -0.0895552709698677, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220003>
      [
        [0.09414546191692352, -0.05349555239081383, -0.09394310414791107, 0.0680985152721405, 0.05514451488852501, 0.10338378697633743, -0.027529548853635788, 0.03738649934530258, 0.12017187476158142, 0.10639435052871704, -0.21103039383888245, 0.09546253830194473, 0.06053944304585457, 0.010116199031472206, 0.13734182715415955, -0.06583978235721588, -0.04140675812959671, 0.1631747931241989, -0.20215000212192535, 0.045266926288604736, 0.09429733455181122, 0.09323552995920181, -0.008121903985738754, 0.0823206678032875, 0.0871056392788887, -0.15799662470817566, 0.13381333649158478, -0.03152550011873245, -0.23124545812606812, ...],
        ...
      ]
    >
  },
  "decoder.blocks.8.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219953>
      [-0.11210184544324875, -0.12243035435676575, -0.18696080148220062, -0.09358573704957962, -0.07174187898635864, -0.09109503775835037, -0.22353070974349976, -0.23647837340831757, -0.009258066304028034, -0.07567327469587326, -0.020744603127241135, 0.015013153664767742, -0.05726751312613487, -0.037477463483810425, -0.02229940891265869, -0.14848092198371887, -0.038814179599285126, 0.02283428981900215, -0.17796941101551056, -0.03959912434220314, 0.026215065270662308, -0.024661418050527573, -0.16912145912647247, -0.022491857409477234, -0.0367843434214592, -0.03149944916367531, -0.07467391341924667, -0.23281385004520416, -0.15074151754379272, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219903>
      [
        [0.07281597703695297, 0.23076365888118744, 0.056254733353853226, -0.007391960825771093, 0.37602195143699646, 0.026575006544589996, -0.0559421107172966, 0.24213534593582153, 0.17022763192653656, 0.008780462667346, 0.008517129346728325, -0.004474610555917025, 0.08918315172195435, -0.0734836533665657, -0.2731582224369049, -0.0711795762181282, -0.09748861193656921, 0.05456811189651489, -0.017072979360818863, 0.02093295007944107, -0.0573551245033741, -0.2868148684501648, -0.0835830420255661, -0.07690536230802536, -0.01711919531226158, -0.1358148157596588, -0.09262753278017044, -0.16049614548683167, ...],
        ...
      ]
    >
  },
  "decoder.blocks.9.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219984>
      [0.05707442760467529, 0.035462647676467896, -0.0991213247179985, 0.13527709245681763, -0.028422338888049126, -0.025333665311336517, 0.009800232946872711, 0.0038071630988270044, 0.2587926983833313, -0.2757236957550049, -0.20594574511051178, -0.10678356885910034, 0.07663259655237198, 0.10082900524139404, 0.09312675893306732, 0.02456960454583168, -0.02361578680574894, 0.027035534381866455, -0.17550106346607208, -0.019421570003032684, 0.17456819117069244, -0.27237164974212646, -0.06578843295574188, 0.7469214200973511, -0.16401293873786926, -0.040414296090602875, 0.0813840925693512, 0.22788934409618378, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219983>
      [
        [0.07092145085334778, -0.1273377686738968, 0.18363283574581146, 0.0030052068177610636, -0.11931692808866501, 0.09142619371414185, 0.09066392481327057, -0.11962020397186279, -0.11546863615512848, -0.2486332207918167, -0.01928895153105259, -0.13211512565612793, 0.012719957157969475, -0.058824148029088974, -0.024515893310308456, -0.06520464271306992, -0.1823996901512146, 0.08205809444189072, -0.14308585226535797, -0.02228454314172268, 0.07376360148191452, 0.1657320261001587, 0.12012247741222382, -0.05113732069730759, 0.09645874798297882, -0.05014803633093834, 0.16555407643318176, ...],
        ...
      ]
    >
  },
  "decoder.blocks.6.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220026>
      [-0.1274530589580536, -0.12059053033590317, -0.007807011716067791, 0.10612983256578445, -0.15291491150856018, 0.02204704098403454, -0.018509021028876305, -0.052053213119506836, -0.12142118811607361, 0.09243933856487274, -0.07746855169534683, -0.2270767092704773, 0.06773963570594788, 0.20025405287742615, 0.08527366816997528, 0.17828650772571564, -0.23929782211780548, 0.08052106946706772, -0.04288453236222267, -0.10904651135206223, -0.07623006403446198, 0.12980422377586365, -0.022937437519431114, 0.1890099197626114, 0.033789169043302536, -0.01818382926285267, -0.09066783636808395, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220025>
      [
        [0.23245984315872192, -0.051963526755571365, 0.03376476839184761, -0.17533107101917267, -0.0015645339153707027, -0.21227991580963135, -0.20261846482753754, 0.2514711320400238, 0.11193699389696121, 0.07263650000095367, 0.1105310469865799, 0.12566789984703064, -0.029312685132026672, -0.18712376058101654, -0.18661442399024963, -0.20233362913131714, -0.25359874963760376, -0.06487743556499481, -0.08297345787286758, 0.03883111849427223, 0.027809424325823784, 0.05575752630829811, 0.0707707554101944, -0.04197012260556221, -8.136677788570523e-4, 0.01103792805224657, ...],
        ...
      ]
    >
  },
  "decoder.blocks.10.self_attention_norm" => %{
    "beta" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219936>
      [0.030510496348142624, 0.006001842673867941, 0.048768121749162674, 0.01165001466870308, 0.005879620555788279, 0.010598479770123959, -0.0672491267323494, 0.025556962937116623, 0.013904724270105362, 6.435069954022765e-4, 0.007581857033073902, 0.012246792204678059, 0.026725852862000465, 0.02789079211652279, 0.04797949641942978, -0.004149633459746838, 0.0409918837249279, 0.034725841134786606, -0.0010700526181608438, 0.01325390674173832, 0.03363116458058357, 0.023286549374461174, 0.02105352096259594, 0.025586696341633797, 0.020323842763900757, 0.006301491055637598, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219937>
      [0.426937460899353, 0.3798982501029968, 0.38925623893737793, 0.36285722255706787, 0.3721630275249481, 0.3487066626548767, 0.5020099878311157, 0.35842880606651306, 0.3820701539516449, 0.32065778970718384, 0.4148608148097992, 0.35868051648139954, 0.3574266731739044, 0.3837886452674866, 0.44628968834877014, 0.397741436958313, 0.3976704776287079, 0.3701581656932831, 0.3779294490814209, 0.39748460054397583, 0.3310501277446747, 0.3544250428676605, 0.38002175092697144, 0.41307657957077026, 0.379832923412323, ...]
    >
  },
  "decoder.blocks.11.self_attention_dropout" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220440>
      [395490763, 1849437528]
    >
  },
  "decoder.blocks.4.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220005>
      [-0.06427578628063202, -0.29860806465148926, -0.11274097114801407, -0.1695093810558319, -0.029283864423632622, 0.015383693389594555, -0.059798579663038254, -0.21982493996620178, -0.11109853535890579, -0.025041809305548668, -0.17913004755973816, -0.04023921862244606, -0.15255160629749298, -0.14760905504226685, -0.05613582208752632, -0.08194784075021744, -0.08518823236227036, -0.10574408620595932, -0.09536109864711761, 0.04650188237428665, -0.24487002193927765, -0.10550493001937866, -0.07493823766708374, 0.3118955194950104, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219923>
      [
        [-4.077995545230806e-4, -0.1200379952788353, -0.012310190126299858, -0.24376054108142853, 0.1328510195016861, 0.13179974257946014, 0.02635245770215988, 0.057356610894203186, -0.06828179955482483, -0.01686907559633255, 0.049044106155633926, -0.3784016966819763, -0.03531080484390259, 0.43567171692848206, 0.02976839430630207, -0.06014109030365944, 0.18706151843070984, -0.050236742943525314, 0.11668948084115982, 0.05957753583788872, -0.14054043591022491, -0.013522407039999962, -0.06838822364807129, ...],
        ...
      ]
    >
  },
  "decoder.blocks.0.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220061>
      [0.1502915918827057, -0.15426146984100342, -0.1466306895017624, -0.09912773221731186, 0.03380264714360237, -0.03444754704833031, -0.0706353709101677, -0.0936073362827301, 0.08110949397087097, 0.031160973012447357, -0.19926859438419342, -0.037245020270347595, 0.0030495061073452234, 0.04989158734679222, -0.0535597987473011, 0.0374077744781971, -0.19088934361934662, -0.08153925091028214, 0.0491158701479435, 0.14187365770339966, -0.11211564391851425, -0.09672139585018158, 0.05310625955462456, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219944>
      [
        [0.3127181828022003, -0.18741346895694733, 0.0980248749256134, -0.030339280143380165, -0.021640362218022346, -0.021060511469841003, -0.17938977479934692, -0.3298454284667969, 0.29462477564811707, 0.016695095226168633, -0.17451533675193787, -0.01856379583477974, 0.015662474557757378, 0.019278528168797493, 0.007864857092499733, 0.19694651663303375, -0.10614901781082153, -0.013053175993263721, 0.014888686127960682, 0.39647337794303894, -0.022225921973586082, 0.03043077513575554, ...],
        ...
      ]
    >
  },
  "decoder.blocks.4.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219996>
      [-0.030168335884809494, 0.10533975064754486, 0.15787462890148163, 0.024759536609053612, -0.006538494024425745, 0.060618676245212555, 0.08839995414018631, -0.13495968282222748, -0.020193777978420258, 0.12939752638339996, -0.08156191557645798, 0.34852737188339233, -0.25281667709350586, 0.0726567953824997, -0.00879716593772173, 0.46894973516464233, -0.20609457790851593, 0.09965331107378006, 0.16798031330108643, 0.21133244037628174, 0.16016334295272827, 0.023227756842970848, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219995>
      [
        [0.05423329025506973, 0.10368772596120834, -0.12026900798082352, 0.2241293340921402, 0.07213354855775833, -0.10475268959999084, -0.098123699426651, -0.03631935641169548, 0.3400250971317291, 0.11668488383293152, 0.3846721351146698, -0.04552015662193298, 0.03707210719585419, 0.060659412294626236, -0.13420982658863068, -0.06594616919755936, 0.17946170270442963, -0.10135768353939056, -8.781739161349833e-4, 0.03128969296813011, 0.10800420492887497, ...],
        ...
      ]
    >
  },
  "decoder.blocks.8.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219955>
      [0.026478445157408714, 0.03058476373553276, 0.03277738764882088, 0.027175817638635635, -0.03420574590563774, -0.04291548207402229, -0.02005288004875183, 0.06033172458410263, 0.042357590049505234, 0.015196949243545532, -0.006372882053256035, 0.014285472221672535, 0.02985285595059395, 0.006489758379757404, -0.03699921444058418, 0.02677823044359684, -0.01978689804673195, 0.029895320534706116, 0.001117934938520193, -0.03488800302147865, 0.03796650841832161, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219956>
      [0.256835401058197, 0.2554992139339447, 0.26428794860839844, 0.2509766221046448, 0.25293001532554626, 0.260743111371994, 0.3623034656047821, 0.2026355266571045, 0.2724631726741791, 0.23681232333183289, 0.26465314626693726, 0.2565948963165283, 0.2509452700614929, 0.26839280128479004, 0.28613126277923584, 0.25516241788864136, 0.26855340600013733, 0.2548842430114746, 0.25679123401641846, 0.25487300753593445, ...]
    >
  },
  "decoder.blocks.6.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220028>
      [0.008094793185591698, -0.012891687452793121, 0.012476509436964989, 0.021194303408265114, 0.04015762358903885, -0.02663881704211235, -0.023752382025122643, -0.001071950071491301, 0.03309759870171547, 0.010285280644893646, -0.006889031268656254, -0.1257532835006714, 9.324409766122699e-4, 0.01171852182596922, -0.043873947113752365, -0.008764470927417278, -0.07170451432466507, -0.012096060439944267, 0.011502828449010849, 0.008124460466206074, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220027>
      [
        [-0.018813427537679672, 0.19313490390777588, 0.05417853593826294, 0.023874085396528244, -0.1469319462776184, -0.03817090019583702, -0.08952698111534119, 0.053204476833343506, 0.03557916358113289, -0.07985074818134308, -0.001789747504517436, -0.14399871230125427, 0.18803372979164124, 0.01738598197698593, 0.038275156170129776, 0.03143403306603432, -0.04185841605067253, 0.07224993407726288, 0.2724269926548004, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220016>
      [-0.0232847947627306, 0.10563581436872482, -0.0531383752822876, -0.09454120695590973, -0.015325434505939484, -0.08506536483764648, -0.07138027250766754, 0.05388682335615158, 0.14111925661563873, 0.1348050981760025, -0.07036365568637848, -0.0036540981382131577, 0.041501376777887344, 0.07138317078351974, -0.1433209776878357, 0.033328648656606674, -0.025909310206770897, -0.15808121860027313, 0.058489684015512466, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219927>
      [
        [0.07660453766584396, 0.005029582418501377, -0.08185179531574249, -0.04126457870006561, 0.06943788379430771, -0.04354039579629898, 0.13279001414775848, 0.057913508266210556, -0.04257570207118988, -0.0920814573764801, -0.2037155032157898, -0.0021956718992441893, 0.06303318589925766, 0.0779477059841156, -0.028110455721616745, -0.22464191913604736, 0.08300850540399551, -0.037264134734869, ...],
        ...
      ]
    >
  },
  "dropout_9" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220441>
      [395490763, 1845682345]
    >
  },
  "lora_28" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220160>
      [
        [-0.037444569170475006, 0.036423712968826294, -0.0372437946498394, -0.014172098599374294, 0.011585015803575516, -0.03949602693319321, 0.0365433432161808, 0.013477451168000698, 0.0563400574028492, -0.009429789148271084, 0.021918367594480515, -0.06163746491074562, -0.04943477734923363, 0.050824280828237534, 0.08861158788204193, -0.013496700674295425, 0.06417960673570633, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220161>
      [
        [-0.007926836609840393, -0.0038086625281721354, 0.004878089297562838, -0.037069905549287796, 2.0947585289832205e-4, 0.016957037150859833, -0.017763324081897736, -0.004888040479272604],
        [0.013251704163849354, 0.04920124635100365, -0.003183032153174281, 0.03596950322389603, 0.013191194273531437, 0.024467937648296356, -0.022460347041487694, 0.004820476286113262],
        ...
      ]
    >
  },
  "dropout_25" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220444>
      [395490763, 1848131803]
    >
  },
  "decoder.blocks.8.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219982>
      [-0.016666432842612267, -0.3908640146255493, -0.14189036190509796, -0.09550853818655014, 0.028818266466259956, -0.03564365208148956, 0.39664602279663086, -0.1003335490822792, -0.12153777480125427, 0.25413286685943604, -0.25467512011528015, 0.2728674113750458, -0.14818769693374634, 0.03464064374566078, -0.01881992444396019, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219981>
      [
        [0.04895172640681267, -0.13535946607589722, 0.08867701888084412, 0.03470441326498985, 0.16805638372898102, -0.04044034704566002, 0.02029840461909771, 0.12461696565151215, 0.038629818707704544, 0.0026324870996177197, 0.1111854836344719, -0.10957732796669006, 0.008841103874146938, 0.22030411660671234, ...],
        ...
      ]
    >
  },
  "decoder.blocks.1.self_attention_dropout" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220445>
      [395490763, 1845238280]
    >
  },
  "lora_13" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220162>
      [
        [-0.005833584349602461, 0.009581577964127064, -0.010804750956594944, -7.156174979172647e-4, 0.034890394657850266, -0.0187480840831995, -0.03598610684275627, 0.001600668765604496, 0.008757724426686764, 0.01462841872125864, -0.013362386263906956, 0.007362341042608023, 0.01468070037662983, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220163>
      [
        [0.004447649698704481, 0.0076615880243480206, 0.012205056846141815, 0.0037861750461161137, -0.015192793682217598, -1.385192445013672e-4, -0.003554451745003462, 0.01283718179911375],
        [-0.015787767246365547, -0.005616679321974516, -0.003988146781921387, -0.005524913314729929, ...],
        ...
      ]
    >
  },
  "lora_20" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220164>
      [
        [-0.021458487957715988, -0.019342025741934776, 0.020958781242370605, 0.023300901055336, -0.0052220518700778484, -0.03552861139178276, 0.03950123116374016, 0.011206896044313908, -0.01779579371213913, 0.026805762201547623, -0.00621938519179821, -0.0074767302721738815, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220165>
      [
        [0.031076638028025627, -0.025085652247071266, -0.03184012696146965, 0.030932730063796043, 0.05506749451160431, -0.03797970712184906, -0.039556726813316345, 0.0018087922362610698],
        [-0.003703518072143197, -0.01143430732190609, -0.012208264321088791, ...],
        ...
      ]
    >
  },
  "decoder.blocks.9.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219940>
      [-0.15674668550491333, -0.05856061354279518, -0.1862010508775711, -0.05574220418930054, 0.05308351293206215, -0.23877263069152832, -0.1725977510213852, -0.16667550802230835, -0.1204790323972702, 0.10092921555042267, -0.1463088095188141, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219898>
      [
        [-0.1263384222984314, 0.10032892227172852, 0.04315217211842537, -0.34024444222450256, 0.03990277275443077, -0.1816384494304657, -0.08722347021102905, -0.09134645760059357, 0.08901876211166382, 0.2486005276441574, ...],
        ...
      ]
    >
  },
  "lora_7" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220166>
      [
        [-0.0018000303534790874, 0.023128356784582138, -0.011031693778932095, 0.017276853322982788, 0.02732015773653984, -0.0026382633950561285, 0.0072501664981245995, -0.0018379141110926867, 0.008119801990687847, -0.005417813081294298, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220167>
      [
        [0.020273525267839432, -0.023160070180892944, 0.01382060069590807, -0.007834143936634064, 0.015298943966627121, -0.008010105229914188, -0.0036666516680270433, 0.01397776696830988],
        [-0.01909354142844677, ...],
        ...
      ]
    >
  },
  "dropout_6" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220452>
      [395490763, 1845355371]
    >
  },
  "decoder.blocks.11.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219962>
      [-0.22222381830215454, 0.054906319826841354, 0.03307081758975983, 0.1580498218536377, 0.0302886962890625, -0.2349749058485031, -0.3064831495285034, -0.11609630286693573, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219961>
      [
        [-0.2175447642803192, 0.060769811272621155, -0.06370636075735092, -0.010534803383052349, 0.03727848827838898, 0.038609497249126434, 0.0018609011312946677, ...],
        ...
      ]
    >
  },
  "decoder.blocks.1.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219966>
      [0.023383773863315582, 0.019925691187381744, -0.010859258472919464, 0.6510787010192871, -0.007127456832677126, 3.0829233583062887e-4, -0.0018755021737888455, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219964>
      [
        [-0.009291327558457851, 0.030902646481990814, 0.077150858938694, 0.03817647323012352, -0.11329539120197296, -0.028751656413078308, ...],
        ...
      ]
    >
  },
  "lora_19" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220168>
      [
        [0.012056661769747734, -0.001176421414129436, -0.03604063019156456, 0.040259018540382385, 0.005427669268101454, 0.01796186901628971, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220169>
      [
        [-0.024819370359182358, -0.009247373789548874, -0.022090233862400055, 0.021909503266215324, -0.012971676886081696, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.self_attention_dropout" => %{
    "key" => #Nx.Tensor<
      u32[2]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220455>
      [395490763, 1845664325]
    >
  },
  "lora_5" => %{
    "lora_a" => #Nx.Tensor<
      f32[8][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220170>
      [
        [-0.01739746332168579, -0.03316907584667206, -0.007022974546998739, 0.010777582414448261, ...],
        ...
      ]
    >,
    "lora_b" => #Nx.Tensor<
      f32[768][8]
      EXLA.Backend<host:0, 0.2581978676.1835401232.220171>
      [
        [0.006508327089250088, 0.007661815267056227, 3.6986847408115864e-4, ...],
        ...
      ]
    >
  },
  "decoder.blocks.11.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219998>
      [0.05557013303041458, -0.023522645235061646, 0.020958656445145607, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219997>
      [
        [0.09672704339027405, 0.02168218418955803, ...],
        ...
      ]
    >
  },
  "embedder.token_embedding" => %{
    "kernel" => #Nx.Tensor<
      f32[50257][768]
      EXLA.Backend<host:0, 0.2581978676.1835401232.219950>
      [
        [-0.11010301113128662, -0.03926672413945198, ...],
        ...
      ]
    >
  },
  "decoder.blocks.4.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220007>
      [0.03581799939274788, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.220008>
      [...]
    >
  },
  "decoder.blocks.10.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.2581978676.1835401236.219931>
      [...]
    >,
    ...
  },
  "decoder.blocks.0.output_norm" => %{...},
  ...
}
```

## Define LoRA Model

Axon keeps the model definition as code. So we need to modify the definition of the GPT2 layers, so it contains the injected LoRA layers. This is the same definition found in the other notebook that trained the LoRA GPT2 model.

```elixir
r = 8
lora_alpha = 16
lora_dropout = 0.05
```

<!-- livebook:{"output":true} -->

```
0.05
```

```elixir
lora_model =
  model
  |> Axon.freeze()
  |> Lorax.inject(%Lorax.Config{
    r: r,
    alpha: lora_alpha,
    dropout: lora_dropout,
    target_key: true,
    target_query: true,
    target_value: true
  })
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"attention_head_mask" => {12, 12}, "attention_mask" => {nil, nil}, "cache" => nil, "input_embeddings" => {nil, nil, 768}, "input_ids" => {nil, nil}, "position_ids" => {nil, nil}}
  outputs: "container_37"
  nodes: 895
>
```

## Inference

As far as I can tell, the model doesn't generate any user that actually exists in the Elixirforums. But a real username may pop up if you run it enough times. The training data can be found in the `data` directory. The structure of every thread goes something like

```
Title: ...

Author: bob

<user submitted text>

[number of likes]
```

```elixir
lora_model_info = %{model: lora_model, params: merged_params, spec: spec}

lora_generation_config =
  Bumblebee.configure(generation_config,
    max_new_tokens: 512,
    strategy: %{type: :multinomial_sampling, top_p: 0.8}
  )

serving =
  Bumblebee.Text.generation(lora_model_info, tokenizer, lora_generation_config,
    compile: [batch_size: 1, sequence_length: 512],
    stream: true,
    defn_options: [compiler: EXLA, lazy_transfers: :always]
  )

Kino.start_child({Nx.Serving, name: Llama, serving: serving})
```

<!-- livebook:{"output":true} -->

```
{:ok, #PID<0.921.0>}
```

```elixir
Nx.Serving.batched_run(Llama, "Title: ") |> Enum.each(&IO.write/1)
```

<!-- livebook:{"output":true} -->

```
{"foo"}}

}

[0 likes]

naicmin:

Thanks for the help. I am still having trouble figuring out how to avoid at least one of the hash tags used to infer the response (or cache all pending responses), but the problem appears to be getting much better.
If it’s a valid response, then you should go back and check it out.
If not, please allow me to help you solve it, or maybe I can help you.
I would love to know the exact address of the cache when that gets logged in, or if this was being set up as the root request, etc.

[1 like]

cladd:

What does it mean for phx.h to log in to a new location when they ask for user info?

[1 like]

naicmin:

Thanks for your help! I’m using phx.h in order to query the user database but will need to pass the route to add a parameter to get to the node so the user is there.
If this is a new request, then you can use this to force phx.h to log in as the root, but I don’t have enough time to figure it out (hopefully I will not see that happening in the near future).

[0 likes]


Title: How to search for an exe string in /etc/cache/exe/exe.ex?

keventty:

How to search for an exe string in /etc/cache/exe/exe.ex? Yes
As per your question, which part of this part is used to enter the output and index? The entry is not in the external JSON cache as it was provided by /etc/cache/exe/exe.ex
If the error happens with the default stack error, then look for it in the web exit prompt.

[0 likes]

joevashd:

It is still unclear if this is a caching issue (or just a network issue).

[0 likes]

keventty:

This is just a very basic guideline: get rid of the default stack header and ignore exe string in /etc/cache/exe/exe.ex.
You will not need to fetch the image when /etc/cache/exe/ex
```

<!-- livebook:{"output":true} -->

```
:ok
```
